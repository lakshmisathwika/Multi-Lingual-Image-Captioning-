{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bharathmogalapu/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [19/Jun/2024 17:25:27] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [19/Jun/2024 17:25:27] \"\u001b[33mGET /main.css HTTP/1.1\u001b[0m\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [19/Jun/2024 17:25:27] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [19/Jun/2024 17:26:02] \"GET /static/image.png HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from flask import Flask, render_template, request, send_file\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from googletrans import Translator\n",
    "from gtts import gTTS\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "with open(\"/Users/bharathmogalapu/Downloads/tokenizer1.pkl\", 'rb') as f:\n",
    "   tokenizer = pickle.load(f)\n",
    "max_length=35\n",
    "from keras.models import load_model \n",
    "model=load_model('/Users/bharathmogalapu/Downloads/archive/model90.h5')\n",
    "\n",
    "\n",
    "def idx_to_word(integer, tokenizer):\n",
    "    for word,index, in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "\n",
    "def predict_caption(model, image, tokenizer, max_length):\n",
    "    # add start tag for generation process\n",
    "    in_text = 'startseq'\n",
    "    # iterate over the max length of sequence\n",
    "    for i in range(max_length):\n",
    "        # encode input sequence\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pad the sequence\n",
    "        sequence = pad_sequences([sequence], max_length)\n",
    "        # predict next word\n",
    "        yhat = model.predict([image, sequence], verbose=0)\n",
    "        # get index with high probability\n",
    "        yhat = np.argmax(yhat)\n",
    "        # convert index to word\n",
    "        word = idx_to_word(yhat, tokenizer)\n",
    "        # stop if word not found\n",
    "        if word is None:\n",
    "            break\n",
    "        # append word as input for generating next word\n",
    "        in_text += \" \" + word\n",
    "        # stop if we reach end tag\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text[8:-6]\n",
    "\n",
    "\n",
    "def new_caption(image_path, model, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Generates a caption for an image using a trained image captioning model.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        model: The trained image captioning model.\n",
    "        tokenizer: The tokenizer used to encode text for the model.\n",
    "        max_length: The maximum length of the generated caption.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated caption.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the Model\n",
    "    x_model = Xception()\n",
    "\n",
    "# Restructure model\n",
    "    x_model = Model(inputs = x_model.inputs , outputs = x_model.layers[-2].output)\n",
    "\n",
    "    # Display the image\n",
    "    img = load_img(image_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = load_img(image_path, target_size=(299, 299))\n",
    "    image = img_to_array(image)\n",
    "    image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "    image = preprocess_input(image)\n",
    "\n",
    "    # Extract features from the image using VGG16\n",
    "    feature = x_model.predict(image, verbose=0)\n",
    "\n",
    "    # Generate caption using the trained model\n",
    "    caption = predict_caption(model, feature, tokenizer, max_length)\n",
    "\n",
    "    return caption\n",
    "\n",
    "# Function to translate text\n",
    "def translate_text(text, dest_language):\n",
    "    translator = Translator()\n",
    "    translated_text = translator.translate(text, dest=dest_language)\n",
    "    return translated_text.text\n",
    "\n",
    "# Function to convert text to speech\n",
    "def text_to_speech(text, language):\n",
    "    tts = gTTS(text=text, lang=language, slow=False)\n",
    "    tts.save(\"static/caption_audio.mp3\")\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return render_template('main.html')\n",
    "\n",
    "@app.route('/', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the uploaded image file\n",
    "    imagefile = request.files['imagefile']\n",
    "    # Save the image file\n",
    "    image_path = './static/' + imagefile.filename\n",
    "    imagefile.save(image_path)\n",
    "    # Get the selected language from the form\n",
    "    selected_language = request.form['language']\n",
    "    # Generate caption for the uploaded image\n",
    "    caption = new_caption(image_path,model,tokenizer,max_length)\n",
    "    # Translate the generated caption\n",
    "    translated_caption = translate_text(caption, selected_language)\n",
    "    # Convert caption to speech\n",
    "    text_to_speech(translated_caption, selected_language)\n",
    "    return render_template('display3.html', prediction=translated_caption, path=image_path)\n",
    "\n",
    "# Route to serve the audio file\n",
    "@app.route('/caption_audio')\n",
    "def caption_audio():\n",
    "    return send_file(\"static/caption_audio.mp3\", as_attachment=True)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
